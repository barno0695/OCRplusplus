0	0
Learning	0
to	0
Predict	0
Peer	0
Review	0
Request	0
Declination	0
0	0
Abstract	0
0	0
We	0
study	0
the	0
problem	0
of	0
finding	0
appropriate	0
re-	0
0	0
viewers	0
who	0
are	0
able	0
to	0
complete	0
timely	0
reviews	0
0	0
and	0
would	0
not	0
say	0
no	0
to	0
the	0
review	0
invitation.	0
0	0
The	0
problem	0
is	0
a	0
central	0
issue	0
in	0
peer	0
review,	0
but	0
0	0
has	0
received	0
little	0
research	0
attention.	0
Different	0
0	0
from	0
most	0
existing	0
studies	0
that	0
focus	0
on	0
matching	0
0	0
given	0
reviewers	0
with	0
a	0
list	0
of	0
papers,	0
we	0
focus	0
on	0
0	0
a	0
more	0
open	0
question:	0
given	0
a	0
paper,	0
how	0
success-	0
0	0
fully	0
we	0
can	0
predict	0
that	0
an	0
expert	0
will	0
accept	0
or	0
de-	0
0	0
cline	0
a	0
review	0
invitation.	0
We	0
formalize	0
the	0
problem	0
0	0
as	0
a	0
ranking	0
factor	0
graph	0
(RankFG)	0
model	0
to	0
pre-	0
0	0
dict	0
the	0
reviewer	0
acceptance	0
for	0
a	0
given	0
paper.	0
We	0
0	0
also	0
develop	0
an	0
interactive	0
learning	0
algorithm	0
for	0
0	0
incrementally	0
learning	0
the	0
ranking	0
function.	0
For	0
0	0
empirical	0
evaluation,	0
we	0
developed	0
a	0
Chrome	0
Ex-	0
0	0
tension	0
for	0
reviewer	0
recommendation	0
and	0
deployed	0
0	0
it	0
in	0
the	0
Google	0
Chrome	0
Web	0
Store.	0
Based	0
on	0
the	0
0	0
feedback/track	0
logs	0
from	0
hundreds	0
of	0
reviewer	0
in-	0
0	0
vitations,	0
the	0
proposed	0
method	0
demonstrates	0
its	0
su-	0
0	0
periority	0
(+5-10%	0
by	0
MAP)	0
over	0
several	0
state-of-	0
0	0
the-art	0
ranking	0
algorithms.	0
0	0
1	0
Introduction	0
0	0
Peer	0
review	0
is	0
an	0
important	0
part	0
of	0
scientific	0
publishing	0
[Ren-	0
0	0
nie,	0
1999;	0
Smith,	0
1997;	0
Kassirer	0
and	0
Campion,	0
1994].	0
In-	0
0	0
deed,	0
many	0
researchers	0
consider	0
peer	0
review	0
as	0
part	0
of	0
their	0
0	0
professional	0
responsibility.	0
Publishing	0
groups	0
also	0
use	0
the	0
0	0
quality	0
of	0
peer	0
reviews	0
as	0
an	0
indicator	0
of	0
the	0
success	0
of	0
a	0
jour-	0
0	0
nal.	0
However,	0
the	0
problem	0
has	0
not	0
received	0
much	0
research	0
0	0
attention.	0
Peer	0
review	0
has	0
long	0
been	0
criticized	0
for	0
being	0
inef-	0
0	0
fective,	0
slow	0
and	0
low-quality.	0
One	0
would	0
expect	0
that	0
experts	0
0	0
with	0
sufficient	0
knowledge	0
would	0
be	0
the	0
best	0
to	0
review	0
a	0
given	0
0	0
paper.	0
However,	0
in	0
practice,	0
our	0
preliminary	0
statistics	0
show	0
0	0
that	0
nearly	0
50%	0
of	0
the	0
review	0
invitations	0
have	0
been	0
declined	0
0	0
(Cf.	0
4	0
for	0
details).	0
Many	0
top	0
experts	0
are	0
inclined	0
to	0
say	0
0	0
no	0
for	0
various	0
reasons.	0
As	0
a	0
result,	0
finding	0
appropriate	0
re-	0
0	0
viewers	0
who	0
are	0
able	0
to	0
complete	0
timely	0
reviews	0
still	0
remains	0
0	0
a	0
challenge.	0
0	0
Quite	0
a	0
few	0
studies	0
have	0
been	0
conducted	0
regarding	0
this	0
0	0
problem.	0
In	0
particular,	0
several	0
efforts	0
have	0
been	0
made	0
for	0
0	0
automating	0
the	0
conference	0
paper-reviewer	0
assignment	0
using	0
0	0
methods	0
such	0
as	0
mining	0
the	0
web	0
[Haym	0
et	0
al.,	0
1999],	0
latent	0
0	0
semantic	0
indexing	0
[Dumais	0
and	0
Nielsen,	0
1992],	0
probabilistic	0
0	0
topic	0
modeling	0
[Karimzadehgan	0
et	0
al.,	0
2008;	0
Mimno	0
and	0
Mc-	0
0	0
Callum,	0
2007],	0
integer	0
linear	0
programming	0
[Karimzadehgan	0
0	0
and	0
Zhai,	0
2009],	0
minimum	0
cost	0
flow	0
[Hartvigsen	0
et	0
al.,	0
1999;	0
0	0
Tang	0
et	0
al.,	0
2012]	0
and	0
a	0
hybrid	0
approach	0
employing	0
do-	0
0	0
main	0
knowledge	0
and	0
a	0
matching	0
model	0
[Sun	0
et	0
al.,	0
2007].	0
0	0
Systems	0
have	0
been	0
also	0
developed	0
to	0
help	0
proposal-reviewer	0
0	0
and	0
paper-reviewer	0
assignment	0
[Hettich	0
and	0
Pazzani,	0
2006;	0
0	0
Conry	0
et	0
al.,	0
2009;	0
Mauro	0
et	0
al.,	0
2005].	0
However,	0
most	0
of	0
0	0
this	0
research	0
focuses	0
on	0
the	0
following	0
setting:	0
given	0
a	0
list	0
of	0
0	0
reviewers	0
and	0
a	0
list	0
of	0
papers,	0
how	0
to	0
find	0
an	0
optimal	0
match-	0
0	0
ing	0
(with	0
some	0
constraints)	0
between	0
reviewers	0
and	0
papers.	0
0	0
In	0
this	0
paper,	0
we	0
study	0
a	0
more	0
open	0
question:	0
given	0
a	0
new	0
0	0
paper,	0
how	0
to	0
find	0
appropriate	0
reviewers	0
who	0
will	0
agree	0
to	0
0	0
review	0
this	0
paper?	0
0	0
The	0
problem	0
is	0
non-trivial.	0
A	0
survey	0
of	0
five	0
biomedi-	0
0	0
cal	0
journals	0
shows	0
that	0
the	0
most	0
important	0
factors	0
for	0
a	0
re-	0
0	0
searcher	0
to	0
accept	0
a	0
review	0
invitation	0
include	0
not	0
just	0
the	0
rel-	0
0	0
evance	0
of	0
the	0
paper	0
topic	0
to	0
the	0
researchers	0
interest,	0
but	0
also	0
0	0
the	0
contribution	0
of	0
the	0
paper	0
to	0
the	0
subject	0
area,	0
and	0
whether	0
0	0
the	0
researcher	0
can	0
learn	0
something	0
new	0
from	0
the	0
paper	0
[Tite	0
0	0
and	0
Schroter,	0
2007].	0
Other	0
reasons	0
for	0
the	0
researchers	0
to	0
de-	0
0	0
cline	0
a	0
review	0
invitation	0
include	0
having	0
too	0
many	0
reviews	0
at	0
0	0
hand	0
and	0
tight	0
deadline	0
for	0
completing	0
the	0
review.	0
However,	0
0	0
technically,	0
it	0
is	0
still	0
unclear	0
how	0
to	0
design	0
an	0
approach	0
to	0
0	0
help	0
deal	0
with	0
the	0
problem.	0
0	0
In	0
this	0
paper,	0
we	0
formalize	0
the	0
problem	0
as	0
a	0
ranking	0
prob-	0
0	0
lem	0
and	0
propose	0
a	0
ranking	0
factor	0
graph	0
(RankFG)	0
model	0
to	0
0	0
predict	0
the	0
willingness	0
of	0
reviewers	0
to	0
review	0
a	0
given	0
paper.	0
0	0
RankFG	0
is	0
able	0
to	0
identify	0
who	0
is	0
at	0
a	0
high	0
risk	0
of	0
declining	0
0	0
a	0
review	0
invitation.	0
It	0
can	0
also	0
interactively	0
adjust	0
the	0
rank-	0
0	0
ing	0
function	0
according	0
to	0
reviewers	0
responses.	0
An	0
efficient	0
0	0
algorithm	0
has	0
been	0
developed	0
for	0
learning	0
and	0
incrementally	0
0	0
updating	0
the	0
ranking	0
function.	0
To	0
empirically	0
evaluate	0
the	0
0	0
proposed	0
methodologies,	0
we	0
developed	0
a	0
Chrome	0
Extension	0
0	0
of	0
reviewer	0
recommendation	0
and	0
deployed	0
it	0
in	0
the	0
Google	0
0	0
Chrome	0
Web	0
Store.	0
More	0
than	0
20	0
journal	0
editors	0
down-	0
0	0
loaded	0
the	0
extension	0
and	0
used	0
it	0
for	0
reviewer	0
recommenda-	0
0	0
tions.	0
Based	0
on	0
their	0
feedback/track	0
logs,	0
we	0
made	0
several	0
in-	0
0	0
teresting	0
discoveries.	0
First,	0
the	0
proposed	0
method	0
can	0
clearly	0
0	0
better	0
predict	0
the	0
declination	0
response,	0
in	0
comparison	0
with	0
0	0
several	0
state-of-the-art	0
ranking	0
algorithms.	0
Second	0
and	0
more	0
0	0
interesting,	0
expertise	0
matching	0
is	0
not	0
very	0
important	0
for	0
pre-	0
0	0
dicting	0
reviewer	0
declination.	0
0	0
To	0
summarize,	0
the	0
contributions	0
of	0
this	0
paper	0
include:	0
0	0
Formalization	0
of	0
the	0
learning	0
to	0
predict	0
declination	0
of	0
0	0
peer	0
review	0
requests.	0
0	0
Proposal	0
of	0
a	0
ranking	0
factor	0
graph	0
(RankFG)	0
model	0
to	0
0	0
predict	0
reviewers	0
responses,	0
and	0
an	0
efficient	0
algorithm	0
0	0
to	0
learn	0
the	0
ranking	0
function.	0
0	0
Empirical	0
validation	0
of	0
the	0
proposed	0
method	0
on	0
a	0
real-	0
0	0
world	0
data	0
set,	0
and	0
implementation	0
of	0
a	0
practical	0
tool	0
for	0
0	0
reviewer	0
recommendation.	0
0	0
2	0
Problem	0
Definition	0
0	0
Given	0
a	0
paper,	0
our	0
goal	0
is	0
find	0
researchers	0
who	0
are	0
qualified	0
0	0
and	0
willing	0
to	0
review	0
this	0
paper.	0
0	0
We	0
consider	0
an	0
academic	0
social	0
network	0
G	0
=	0
(V,	0
E),	0
0	0
where	0
V	0
is	0
a	0
set	0
of	0
|V	0
|	0
=	0
N	0
researchers	0
and	0
E	0
V	0
V	0
is	0
0	0
a	0
set	0
of	0
relationships	0
between	0
researchers.	0
There	0
can	0
be	0
vari-	0
0	0
ous	0
kinds	0
of	0
relationships,	0
for	0
example,	0
collaborations,	0
same-	0
0	0
affiliation,	0
and	0
same-nationality.	0
Let	0
x	0
i	0
denote	0
researcher	0
0	0
v	0
i	0
s	0
attributes,	0
which	0
could	0
be	0
ones	0
research	0
interests,	0
re-	0
0	0
search	0
experience,	0
or	0
simply	0
the	0
number	0
of	0
his/her	0
publica-	0
0	0
tions.	0
We	0
use	0
X	0
=	0
{x	0
1	0
,	0
,	0
x	0
N	0
}	0
to	0
denote	0
the	0
attributes	0
of	0
0	0
all	0
researchers.	0
Given	0
this,	0
we	0
define	0
our	0
problem	0
of	0
review	0
0	0
declination	0
prediction.	0
0	0
Problem	0
1	0
Review	0
Declination	0
Prediction.	0
Let	0
G	0
=	0
0	0
(V,	0
E,	0
X)	0
be	0
an	0
attribute	0
augmented	0
academic	0
social	0
net-	0
0	0
work.	0
Given	0
a	0
particular	0
paper	0
p,	0
the	0
goal	0
is	0
to	0
find	0
a	0
pre-	0
0	0
dictive	0
function	0
such	0
that	0
we	0
can	0
suggest	0
researchers	0
of	0
high	0
0	0
relevance	0
to	0
paper	0
p	0
and	0
of	0
low	0
risk	0
of	0
declining	0
the	0
review	0
0	0
invitation,	0
i.e.,	0
0	0
f	0
:	0
(G,	0
p)	0
Y	0
0	0
(1)	0
0	0
where	0
Y	0
=	0
{y	0
1	0
,	0
,	0
y	0
N	0
}	0
represents	0
the	0
prediction	0
results	0
0	0
for	0
all	0
researchers	0
in	0
the	0
network	0
G	0
and	0
y	0
k	0
{0,	0
1}	0
is	0
a	0
0	0
binary	0
score	0
indicating	0
whether	0
reviewer	0
v	0
k	0
V	0
has	0
a	0
high	0
0	0
risk	0
of	0
declining	0
the	0
invitation.	0
0	0
The	0
predictive	0
function	0
f	0
takes	0
the	0
network	0
G	0
as	0
input,	0
0	0
which	0
means	0
that	0
we	0
should	0
consider	0
the	0
network	0
informa-	0
0	0
tion	0
in	0
designing	0
the	0
prediction	0
function.	0
We	0
also	0
demon-	0
0	0
strate	0
that	0
the	0
network	0
information	0
is	0
very	0
useful	0
and	0
can	0
help	0
0	0
improve	0
the	0
prediction	0
accuracy.	0
0	0
3	0
Approach	0
Framework	0
0	0
The	0
common	0
approaches	0
for	0
finding	0
appropriate	0
reviewers	0
0	0
focus	0
on	0
estimating	0
the	0
relevance	0
of	0
a	0
paper	0
to	0
potential	0
re-	0
0	0
viewers	0
research	0
interests.	0
This	0
can	0
be	0
done	0
by	0
different	0
0	0
ways	0
of	0
calculating	0
the	0
similarity	0
between	0
researchers	0
inter-	0
0	0
ests	0
and	0
the	0
paper	0
content.	0
The	0
more	0
important	0
problem	0
we	0
0	0
want	0
to	0
solve	0
is	0
how	0
to	0
predict	0
who	0
will	0
accept/decline	0
the	0
0	0
review	0
invitation	0
after	0
retrieving	0
some	0
candidate	0
reviewers.	0
0	0
At	0
a	0
high	0
level,	0
the	0
proposed	0
approach	0
framework	0
consists	0
0	0
of	0
three	0
stages.	0
0	0
Candidate	0
Generation.	0
First,	0
given	0
a	0
submitted	0
paper	0
0	0
p	0
and	0
its	0
keywords	0
list	0
K	0
p	0
,	0
we	0
extract	0
potential	0
reviewer	0
0	0
candidates	0
through	0
content	0
similarity.	0
0	0
Declination	0
Predication.	0
Second,	0
we	0
present	0
a	0
rank-	0
0	0
ing	0
factor	0
graph	0
(RankFG)	0
model,	0
which	0
takes	0
the	0
se-	0
0	0
lected	0
candidates	0
reviewers	0
as	0
input	0
and	0
predicts	0
who	0
0	0
has	0
a	0
high	0
risk	0
of	0
declining	0
the	0
review.	0
0	0
Interactive	0
Learning.	0
Third,	0
having	0
collected	0
review-	0
0	0
ers	0
responses	0
(either	0
agree	0
or	0
decline),	0
the	0
RankFG	0
uses	0
0	0
an	0
interactive	0
learning	0
algorithm	0
to	0
update	0
its	0
parameter	0
0	0
configuration	0
in	0
the	0
predictive	0
function	0
incrementally.	0
0	0
3.1	0
Candidate	0
Generation	0
0	0
Given	0
a	0
paper	0
p	0
in	0
a	0
peer	0
review	0
process,	0
we	0
first	0
extract	0
a	0
0	0
number	0
of	0
keywords	0
from	0
the	0
paper.	0
The	0
extraction	0
is	0
done	0
0	0
using	0
a	0
keyword	0
extraction	0
tool	0
[Zhang	0
et	0
al.,	0
2006].	0
The	0
0	0
authors	0
may	0
also	0
provide	0
a	0
set	0
of	0
keywords.	0
In	0
such	0
case,	0
0	0
we	0
will	0
combine	0
the	0
extracted	0
keywords	0
and	0
the	0
authors	0
pro-	0
0	0
vided	0
keywords	0
together.	0
0	0
Then	0
we	0
use	0
a	0
language	0
model	0
to	0
retrieve	0
relevant	0
re-	0
0	0
searchers	0
from	0
an	0
online	0
publication	0
database.	0
Language	0
0	0
model	0
is	0
one	0
of	0
the	0
state-of-the-art	0
approaches	0
in	0
informa-	0
0	0
tion	0
retrieval.	0
It	0
interprets	0
the	0
relevance	0
between	0
a	0
document	0
0	0
and	0
a	0
query	0
word	0
as	0
a	0
generative	0
probability:	0
0	0
P	0
(w|d)	0
=	0
0	0
N	0
d	0
0	0
N	0
d	0
+	0
0	0
0	0
tf	0
(w,	0
d)	0
0	0
N	0
d	0
0	0
+(1	0
0	0
N	0
d	0
0	0
N	0
d	0
+	0
0	0
)	0
0	0
tf	0
(w,	0
D)	0
0	0
N	0
D	0
0	0
(2)	0
0	0
where	0
N	0
d	0
is	0
the	0
number	0
of	0
word	0
tokens	0
in	0
document	0
d,	0
0	0
tf	0
(w,	0
d)	0
is	0
the	0
word	0
frequency	0
(i.e.,	0
occurrence	0
number)	0
of	0
0	0
word	0
w	0
in	0
d,	0
N	0
D	0
is	0
the	0
number	0
of	0
word	0
tokens	0
in	0
the	0
entire	0
0	0
collection,	0
and	0
tf	0
(w,	0
D)	0
is	0
the	0
word	0
frequency	0
of	0
word	0
w	0
in	0
0	0
the	0
collection	0
D.	0
is	0
the	0
Dirichlet	0
smoothing	0
factor	0
and	0
is	0
0	0
commonly	0
set	0
according	0
to	0
the	0
average	0
document	0
length	0
in	0
0	0
the	0
collection	0
[Zhai	0
and	0
Lafferty,	0
2001].	0
Further,	0
the	0
proba-	0
0	0
bility	0
of	0
the	0
document	0
model	0
d	0
generating	0
a	0
query	0
q	0
can	0
be	0
0	0
defined	0
as	0
P	0
(q|d)	0
=	0
wq	0
P	0
(w|d).	0
Adapted	0
to	0
our	0
setting,	0
0	0
we	0
replace	0
document	0
d	0
in	0
Eq.	0
2	0
with	0
a	0
researchers	0
content	0
0	0
information	0
(e.g.,	0
all	0
published	0
papers	0
by	0
the	0
researcher)	0
and	0
0	0
q	0
with	0
the	0
extracted	0
keywords	0
from	0
paper	0
p.	0
0	0
3.2	0
Declination	0
Prediction	0
0	0
After	0
retrieving	0
candidate	0
reviewers,	0
we	0
propose	0
a	0
ranking	0
0	0
factor	0
graph	0
(RankFG)	0
model	0
to	0
predict	0
how	0
likely	0
the	0
re-	0
0	0
viewer	0
is	0
to	0
accept	0
or	0
decline	0
the	0
review	0
invitation.	0
The	0
0	0
graphical	0
model	0
RankFG	0
consists	0
of	0
two	0
layers	0
of	0
variables:	0
0	0
observations	0
and	0
latent	0
variables.	0
In	0
our	0
problem,	0
each	0
ob-	0
0	0
servation	0
represent	0
a	0
paper-reviewer	0
pair	0
{(p,	0
v	0
i	0
)}.	0
Each	0
ob-	0
0	0
servation	0
is	0
associated	0
with	0
a	0
latent	0
variable	0
y	0
i	0
to	0
represent	0
0	0
whether	0
the	0
reviewer	0
will	0
agree	0
or	0
decline	0
to	0
review	0
this	0
pa-	0
0	0
per.	0
Local	0
factor	0
functions	0
are	0
defined	0
to	0
capture	0
the	0
rela-	0
0	0
tionships	0
between	0
an	0
observation	0
and	0
its	0
corresponding	0
latent	0
0	0
variable.	0
Moreover,	0
observations	0
might	0
be	0
correlated	0
with	0
0	0
each	0
other.	0
For	0
example,	0
candidate	0
researchers	0
with	0
the	0
same	0
0	0
nationality	0
may	0
say	0
no	0
at	0
the	0
same	0
time.	0
Figure	0
1	0
shows	0
0	0
an	0
preliminary	0
statistics	0
on	0
our	0
collected	0
real	0
data	0
(Cf.	0
4	0
for	0
0	0
details	0
of	0
the	0
data	0
sets).	0
We	0
see	0
that,	0
on	0
average,	0
the	0
probabil-	0
0	0
ity	0
that	0
a	0
reviewer	0
will	0
decline	0
the	0
invitation	0
almost	0
doubles	0
0	0
if	0
another	0
reviewer	0
of	0
the	0
same	0
nationality	0
has	0
declined	0
the	0
0	0
invitation.	0
In	0
RankFG,	0
such	0
kind	0
of	0
correlations	0
can	0
be	0
de-	0
0	0
fined	0
as	0
correlation	0
factor	0
functions	0
among	0
latent	0
variables.	0
0	0
#	0
reviewers	0
with	0
same	0
nationality	0
decline	0
0	0
0	0
0	0
1	0
0	0
2	0
0	0
3	0
0	0
4	0
0	0
5	0
0	0
6	0
0	0
7	0
0	0
Decline	0
percentage	0
0	0
0	0
0	0
0.1	0
0	0
0.2	0
0	0
0.3	0
0	0
0.4	0
0	0
0.5	0
0	0
0.6	0
0	0
0.7	0
0	0
0.8	0
0	0
0.9	0
0	0
1	0
0	0
Figure	0
1:	0
Declination	0
probability	0
conditioned	0
on	0
the	0
number	0
0	0
of	0
reviewers	0
of	0
same	0
nationality	0
who	0
have	0
already	0
declined.	0
0	0
More	0
specifically,	0
we	0
have	0
the	0
following	0
factor	0
definitions	0
in	0
0	0
our	0
problem.	0
0	0
Local	0
factor	0
function:	0
Captures	0
the	0
characteristics	0
of	0
0	0
each	0
paper-reviewer	0
pair,	0
including	0
a	0
relevance	0
score	0
between	0
0	0
the	0
paper	0
and	0
the	0
reviewer,	0
and	0
any	0
attributes	0
associated	0
with	0
0	0
the	0
reviewer.	0
Defined	0
as	0
an	0
exponential	0
function	0
0	0
f	0
(p,	0
v	0
i	0
,	0
y	0
i	0
)	0
=	0
0	0
1	0
0	0
Z	0
a	0
0	0
exp	0
0	0
0	0
0	0
k	0
0	0
k	0
k	0
(p,	0
v	0
i	0
,	0
y	0
i	0
)	0
0	0
0	0
(3)	0
0	0
where	0
k	0
(.)	0
is	0
the	0
k	0
th	0
feature	0
function	0
defined	0
between	0
p	0
0	0
and	0
v	0
i	0
with	0
respect	0
to	0
the	0
value	0
of	0
y	0
i	0
;	0
k	0
is	0
the	0
weight	0
of	0
the	0
0	0
feature;	0
Z	0
a	0
is	0
a	0
normalization	0
factor.	0
0	0
Correlation	0
factor	0
function:	0
Captures	0
the	0
correlation	0
be-	0
0	0
tween	0
latent	0
variables.	0
Also	0
defined	0
as	0
an	0
exponential	0
func-	0
0	0
tion	0
0	0
g(y	0
i	0
,	0
y	0
j	0
)	0
=	0
0	0
1	0
0	0
Z	0
b	0
0	0
exp	0
0	0
0	0
0	0
l	0
0	0
l	0
l	0
(y	0
i	0
,	0
y	0
j	0
)	0
0	0
0	0
(4)	0
0	0
where	0
i	0
(.)	0
is	0
the	0
l	0
th	0
feature	0
function	0
defined	0
between	0
y	0
i	0
and	0
0	0
y	0
j	0
;	0
l	0
is	0
the	0
weight	0
of	0
the	0
feature;	0
Z	0
b	0
is	0
a	0
normalization	0
factor.	0
0	0
By	0
integrating	0
the	0
defined	0
factor	0
functions,	0
and	0
also	0
fol-	0
0	0
lowing	0
the	0
Markov	0
assumption	0
[Kindermann	0
et	0
al.,	0
1980],	0
we	0
0	0
can	0
define	0
the	0
following	0
log-likelihood	0
objective	0
function:	0
0	0
log	0
P	0
(Y	0
|X,	0
)	0
=	0
0	0
0	0
yiY	0
0	0
0	0
k	0
0	0
k	0
k	0
(p,	0
v	0
i	0
,	0
y	0
i	0
)	0
0	0
+	0
0	0
0	0
vivj	0
0	0
0	0
l	0
0	0
l	0
l	0
(y	0
i	0
,	0
y	0
j	0
)	0
log	0
Z	0
0	0
(5)	0
0	0
where	0
Z	0
=	0
Z	0
a	0
Z	0
b	0
is	0
the	0
normalization	0
factor;	0
v	0
i	0
v	0
j	0
indi-	0
0	0
cates	0
that	0
there	0
is	0
a	0
defined	0
correlation	0
between	0
reviewer	0
v	0
i	0
0	0
and	0
v	0
j	0
;	0
=	0
({},	0
{})	0
are	0
parameters	0
to	0
estimate.	0
0	0
Feature	0
Definitions	0
0	0
Now	0
we	0
introduce	0
possible	0
ways	0
of	0
defining	0
the	0
factor	0
func-	0
0	0
tions	0
k	0
(p,	0
v	0
i	0
,	0
y	0
i	0
)	0
and	0
l	0
(y	0
i	0
,	0
y	0
j	0
).	0
In	0
principle,	0
the	0
factor	0
func-	0
0	0
tions	0
can	0
be	0
instantiated	0
in	0
different	0
ways	0
to	0
reflect	0
our	0
prior	0
0	0
knowledge	0
or	0
intuitions	0
for	0
different	0
applications.	0
It	0
can	0
be	0
0	0
defined	0
as	0
either	0
binary	0
or	0
a	0
real-valued.	0
In	0
total,	0
we	0
de-	0
0	0
fine	0
nine	0
feature	0
functions	0
that	0
can	0
be	0
divided	0
into	0
three	0
cat-	0
0	0
egories:	0
Basic	0
statistics,	0
Expertise	0
matching,	0
and	0
Organiza-	0
0	0
tion.	0
0	0
Basic	0
statistics.	0
We	0
define	0
a	0
set	0
of	0
statistics	0
features	0
for	0
0	0
each	0
potential	0
reviewer,	0
including	0
their	0
h-index,	0
publi-	0
0	0
cation	0
number,	0
citation	0
number,	0
and	0
length	0
of	0
research	0
0	0
experience.	0
0	0
Expertise	0
matching.	0
We	0
calculate	0
the	0
similarity	0
be-	0
0	0
tween	0
the	0
papers	0
keywords	0
and	0
the	0
reviewers	0
research	0
0	0
interests.	0
Four	0
features	0
are	0
defined	0
in	0
this	0
category:	0
0	0
the	0
number	0
of	0
common	0
interests,	0
percentage	0
of	0
com-	0
0	0
mon	0
interests,	0
percentage	0
of	0
common	0
interests	0
among	0
0	0
the	0
papers	0
keywords,	0
and	0
percentage	0
of	0
common	0
in-	0
0	0
terets	0
among	0
the	0
reviewers	0
interests.	0
0	0
Organization.	0
We	0
define	0
a	0
binary	0
feature	0
to	0
indicate	0
0	0
whether	0
the	0
reviewer	0
comes	0
from	0
academia	0
or	0
industry.	0
0	0
Two	0
correlation	0
factors	0
are	0
defined	0
according	0
to	0
reviewers	0
0	0
attributes.	0
The	0
first	0
one	0
correlation	0
factor	0
represents	0
whether	0
0	0
two	0
reviewers	0
are	0
of	0
the	0
same	0
nationality,	0
and	0
the	0
second	0
cor-	0
0	0
relation	0
factor	0
represents	0
whether	0
the	0
two	0
reviewers	0
have	0
the	0
0	0
same	0
affiliation.	0
0	0
Model	0
learning	0
0	0
Training	0
RankFG	0
model	0
involves	0
finding	0
a	0
parameter	0
con-	0
0	0
figuration	0
=	0
({},	0
{})	0
from	0
a	0
given	0
training	0
dataset,	0
0	0
such	0
that	0
the	0
log-likelihood	0
objective	0
function	0
L()	0
=	0
0	0
log	0
P	0
(Y	0
|X,	0
)	0
can	0
be	0
maximized,	0
0	0
=	0
arg	0
max	0
0	0
0	0
log	0
P	0
(Y	0
|X,	0
)	0
0	0
(6)	0
0	0
This	0
optimization	0
problem	0
can	0
be	0
solved	0
using	0
a	0
gradient	0
0	0
ascent	0
algorithm	0
(or	0
a	0
Newton-Raphson	0
method).	0
The	0
gradi-	0
0	0
ent	0
of	0
each	0
parameter	0
wrt	0
L()	0
is	0
0	0
L()	0
0	0
i	0
0	0
=	0
0	0
0	0
j	0
0	0
f	0
(x	0
i	0
,	0
y	0
i	0
)	0
0	0
Z()	0
0	0
Z()	0
0	0
=	0
E[(x	0
i	0
,	0
y	0
i	0
)]	0
E	0
P	0
(xi,y	0
i	0
)	0
[(x	0
i	0
,	0
y	0
i	0
)]	0
0	0
(7)	0
0	0
In	0
this	0
equation,	0
we	0
use	0
to	0
indicate	0
both	0
and	0
.	0
The	0
0	0
first	0
term	0
E[(x	0
i	0
,	0
y	0
i	0
)]	0
in	0
Eq.	0
7	0
is	0
easy	0
to	0
calculate.	0
However,	0
0	0
the	0
second	0
term	0
is	0
unmanageable	0
to	0
estimate	0
because	0
of	0
the	0
0	0
difficulty	0
in	0
determining	0
the	0
marginal	0
probability	0
P	0
(x	0
i	0
,	0
y	0
i	0
),	0
0	0
as	0
the	0
graph	0
structure	0
may	0
contain	0
cycles.	0
There	0
are	0
several	0
0	0
methods	0
to	0
approximately	0
solve	0
the	0
problem.	0
In	0
our	0
work,	0
we	0
0	0
choose	0
the	0
sum-product	0
algorithm	0
[Kschischang	0
et	0
al.,	0
2001]	0
0	0
(also	0
known	0
as	0
Loop	0
Belief	0
Propagation	0
(LBP)	0
[Yedidia	0
et	0
0	0
al.,	0
2000]).	0
To	0
perform	0
the	0
sum-product	0
algorithm,	0
we	0
first	0
0	0
derive	0
a	0
factor	0
graph	0
from	0
the	0
original	0
graph	0
G.	0
Factor	0
graph	0
0	0
model	0
represents	0
the	0
factorization	0
of	0
a	0
function,	0
which	0
means	0
0	0
the	0
likelihood	0
P	0
(Y	0
|X)	0
in	0
our	0
framework.	0
We	0
can	0
flexibly	0
0	0
add	0
factor	0
nodes	0
for	0
feature	0
functions.	0
Then	0
we	0
apply	0
the	0
0	0
sum-product	0
algorithm	0
to	0
the	0
factor	0
graph	0
to	0
compute	0
the	0
0	0
approximate	0
marginal	0
distributions.	0
The	0
algorithm	0
operates	0
0	0
message	0
passing	0
according	0
to	0
the	0
sum-product	0
update	0
rule:	0
0	0
the	0
message	0
sent	0
from	0
variable	0
v	0
to	0
factor	0
f	0
(or	0
g)	0
is	0
the	0
prod-	0
0	0
uct	0
of	0
the	0
local	0
function	0
at	0
v	0
received	0
from	0
all	0
factors	0
other	0
0	0
than	0
f	0
,	0
and	0
the	0
message	0
sent	0
from	0
factor	0
f	0
to	0
variable	0
v	0
is	0
the	0
0	0
sum	0
of	0
all	0
factor	0
functions	0
associated	0
with	0
v,	0
i.e.,	0
0	0
vf	0
(x	0
v	0
)	0
=	0
0	0
0	0
f	0
N	0
(v)\{f	0
}	0
0	0
f	0
v	0
(x	0
v	0
)	0
0	0
(8)	0
0	0
f	0
v	0
(x	0
v	0
)	0
=	0
0	0
0	0
xv	0
0	0
f	0
(x	0
f	0
)	0
0	0
0	0
v	0
N	0
(f	0
)\{v}	0
0	0
v	0
f	0
(v	0
)	0
(9)	0
0	0
Algorithm	0
1	0
Learning	0
algorithm	0
for	0
RankFG.	0
0	0
Input:	0
Query	0
papers	0
Q	0
=	0
{p}	0
with	0
corresponding	0
keywords	0
0	0
{K	0
p	0
},	0
G	0
=	0
(V,	0
E,	0
X),	0
and	0
the	0
learning	0
rate	0
;	0
0	0
Output:	0
learned	0
parameters	0
;	0
0	0
0;	0
0	0
repeat	0
0	0
for	0
p	0
Q	0
and	0
K	0
p	0
do	0
0	0
L	0
initialization	0
list;	0
0	0
Factor	0
graph	0
F	0
G	0
BuildF	0
actorGraph(L);	0
0	0
repeat	0
0	0
for	0
v	0
i	0
L	0
do	0
0	0
Update	0
the	0
messages	0
of	0
v	0
i	0
by	0
Eq.	0
8	0
and	0
9;	0
0	0
end	0
for	0
0	0
until	0
all	0
messages	0
do	0
not	0
change;	0
0	0
for	0
i	0
do	0
0	0
Calculate	0
gradient	0
i	0
according	0
to	0
Eq.	0
7;	0
0	0
Update	0
new	0
=	0
old	0
+	0
i	0
;	0
0	0
end	0
for	0
0	0
end	0
for	0
0	0
until	0
converge;	0
0	0
where	0
N	0
(v)	0
are	0
neighborhood	0
factors	0
of	0
variable	0
v	0
and	0
N	0
(f	0
)	0
0	0
are	0
neighborhood	0
variables	0
of	0
factor	0
v;	0
x	0
f	0
is	0
the	0
set	0
of	0
argu-	0
0	0
ments	0
of	0
f	0
(.);	0
0	0
0	0
x	0
means	0
the	0
summation	0
over	0
all	0
variables	0
0	0
expect	0
x.	0
Algorithm	0
1	0
describes	0
the	0
learning	0
process	0
of	0
the	0
0	0
RankFG	0
model.	0
In	0
each	0
iteration,	0
messages	0
are	0
updated	0
se-	0
0	0
quentially	0
in	0
a	0
certain	0
order.	0
We	0
randomly	0
select	0
a	0
node	0
as	0
the	0
0	0
root	0
and	0
perform	0
a	0
breadth-first	0
search	0
on	0
the	0
factor	0
graph	0
to	0
0	0
construct	0
a	0
tree.	0
We	0
update	0
the	0
messages	0
from	0
the	0
leaves	0
to	0
0	0
the	0
root,	0
then	0
from	0
the	0
root	0
to	0
the	0
leaves.	0
The	0
updating	0
pro-	0
0	0
cess	0
continues	0
until	0
the	0
convergence	0
or	0
the	0
number	0
of	0
itera-	0
0	0
tions	0
is	0
large	0
enough.	0
Based	0
on	0
the	0
received	0
messages	0
from	0
0	0
factors,	0
we	0
can	0
calculate	0
the	0
marginal	0
probabilities	0
for	0
each	0
0	0
variable.	0
Then	0
we	0
compute	0
the	0
gradient	0
according	0
to	0
Eq.	0
7	0
0	0
and	0
update	0
the	0
parameters	0
by	0
new	0
=	0
old	0
+	0
i	0
,	0
with	0
the	0
0	0
learning	0
step	0
.	0
0	0
Declination	0
Prediction	0
0	0
Given	0
the	0
observed	0
value	0
x	0
and	0
the	0
learned	0
parameters	0
,	0
the	0
0	0
declination	0
prediction	0
is	0
to	0
find	0
the	0
most	0
likely	0
configuration	0
0	0
of	0
Y	0
p	0
for	0
a	0
given	0
paper	0
p.	0
This	0
can	0
be	0
obtained	0
by:	0
0	0
Y	0
p	0
=	0
arg	0
max	0
0	0
Yp	0
0	0
P	0
(Y	0
p	0
|X,	0
)	0
0	0
(10)	0
0	0
For	0
inference,	0
we	0
use	0
the	0
max-sum	0
algorithm	0
to	0
find	0
the	0
0	0
values	0
of	0
Y	0
p	0
that	0
maximize	0
the	0
likelihood.	0
This	0
max-sum	0
0	0
algorithm	0
is	0
similar	0
to	0
the	0
sum-product	0
algorithm,	0
except	0
for	0
0	0
calculating	0
the	0
message	0
according	0
to	0
max	0
instead	0
of	0
sum	0
in	0
0	0
message	0
passing	0
functions	0
Eqs.	0
8	0
and	0
9.	0
0	0
3.3	0
Interactive	0
Learning	0
0	0
In	0
our	0
framework,	0
interactive	0
learning	0
refers	0
to	0
update	0
the	0
0	0
ranking	0
model	0
base	0
on	0
reviewer	0
responses.	0
The	0
idea	0
is	0
to	0
0	0
record	0
whether	0
the	0
invited	0
reviewers	0
accept	0
or	0
reject	0
the	0
re-	0
0	0
view	0
invitation,	0
and	0
then	0
incrementally	0
adjust	0
parameters	0
in	0
0	0
the	0
ranking	0
model	0
according	0
to	0
this	0
feedback.	0
The	0
algorithm	0
0	0
supports	0
both	0
online	0
interactive	0
update	0
and	0
offline	0
complete	0
0	0
update.	0
0	0
The	0
technical	0
challenge	0
of	0
interactive	0
learning	0
is	0
how	0
to	0
0	0
update	0
the	0
learned	0
RankFG	0
model	0
efficiently	0
and	0
effectively.	0
0	0
We	0
use	0
an	0
algorithm	0
to	0
incrementally	0
update	0
the	0
parameters,	0
0	0
which	0
mainly	0
solves	0
the	0
problem	0
of	0
how	0
to	0
calculate	0
the	0
gra-	0
0	0
dient.	0
According	0
to	0
Eq.	0
7,	0
for	0
the	0
first	0
term,	0
it	0
is	0
easy	0
to	0
0	0
obtain	0
an	0
incremental	0
estimation,	0
i.e.,	0
0	0
E	0
new	0
[.]	0
=	0
0	0
N	0
0	0
N	0
+	0
1	0
0	0
E	0
old	0
[.]	0
+	0
0	0
1	0
0	0
N	0
+	0
1	0
0	0
0	0
k	0
0	0
k	0
k	0
(x	0
N	0
+1	0
,	0
y	0
N	0
+1	0
)	0
0	0
where	0
{	0
k	0
k	0
(x	0
N	0
+1	0
,	0
y	0
N	0
+1	0
)}	0
denotes	0
factor	0
functions	0
defined	0
0	0
for	0
the	0
new	0
learning	0
instance	0
with	0
the	0
reviewers	0
feedback	0
0	0
(y	0
N	0
+1	0
=	0
1	0
for	0
agree	0
or	0
0	0
for	0
decline).	0
For	0
the	0
second	0
term,	0
it	0
0	0
is	0
again	0
unmanageable	0
to	0
compute	0
the	0
marginal	0
probabilities.	0
0	0
Since	0
it	0
is	0
very	0
time-consuming	0
to	0
perform	0
global	0
message	0
0	0
passing	0
on	0
the	0
complete	0
factor	0
graph,	0
we	0
can	0
approximate	0
it	0
0	0
by	0
performing	0
a	0
local	0
message	0
passing.	0
A	0
similar	0
idea	0
has	0
0	0
been	0
previously	0
used	0
in	0
[Wu	0
et	0
al.,	0
2013].	0
Specifically,	0
we	0
0	0
first	0
add	0
new	0
factor	0
nodes	0
(variable	0
and	0
factor	0
nodes)	0
to	0
the	0
0	0
factor	0
graph	0
built	0
before.	0
Then	0
we	0
perform	0
local	0
message	0
0	0
passing	0
which	0
starts	0
from	0
the	0
new	0
variable	0
node	0
y	0
N	0
+1	0
and	0
0	0
terminates	0
within	0
l	0
steps.	0
More	0
precisely,	0
we	0
take	0
the	0
new	0
0	0
variable	0
node	0
y	0
N	0
+1	0
as	0
root	0
node,	0
begin	0
by	0
calculating	0
mes-	0
0	0
sages	0
y	0
N	0
+1	0
f	0
,	0
and	0
then	0
send	0
messages	0
to	0
all	0
of	0
its	0
neigh-	0
0	0
borhood	0
factor	0
nodes.	0
The	0
messages	0
are	0
propagated	0
accord-	0
0	0
ing	0
to	0
a	0
function	0
similar	0
to	0
Eqs.	0
8	0
and	0
9	0
and	0
terminates	0
when	0
0	0
the	0
path	0
length	0
exceeds	0
l.	0
After	0
forward	0
passing,	0
we	0
then	0
per-	0
0	0
form	0
a	0
backward	0
messages	0
passing,	0
which	0
finally	0
propagates	0
0	0
all	0
messages	0
back	0
to	0
the	0
root	0
node	0
y	0
N	0
+1	0
.	0
In	0
this	0
way,	0
based	0
0	0
on	0
the	0
messages	0
sent	0
between	0
variables	0
and	0
factors,	0
we	0
can	0
0	0
calculate	0
an	0
approximate	0
value	0
of	0
the	0
marginal	0
probabilities	0
0	0
of	0
the	0
newly	0
added	0
factors/variables.	0
Accordingly,	0
we	0
can	0
es-	0
0	0
timate	0
the	0
second	0
term	0
of	0
Eq.	0
7,	0
and	0
can	0
further	0
estimate	0
the	0
0	0
gradient.	0
0	0
4	0
Experimental	0
Results	0
0	0
To	0
empirically	0
evaluate	0
the	0
proposed	0
methodologies,	0
we	0
de-	0
0	0
veloped	0
an	0
Chrome	0
Extension	0
for	0
reviewer	0
recommendation	0
0	0
and	0
deployed	0
it	0
in	0
the	0
Google	0
Chrome	0
Web	0
Store.	0
More	0
0	0
than	0
20	0
journal	0
editors	0
downloaded	0
the	0
app	0
and	0
used	0
it	0
for	0
0	0
reviewer	0
recommendations.	0
0	0
4.1	0
Experimental	0
Setup	0
0	0
Datasets	0
0	0
We	0
evaluate	0
our	0
method	0
from	0
two	0
different	0
perspectives:	0
Rel-	0
0	0
evance	0
and	0
Response.	0
In	0
Relevance,	0
we	0
focus	0
on	0
evaluating	0
0	0
how	0
the	0
proposed	0
method	0
can	0
find	0
experts	0
who	0
are	0
able	0
to	0
0	0
review	0
the	0
given	0
paper,	0
and	0
in	0
Response,	0
we	0
focus	0
on	0
evalu-	0
0	0
ating	0
how	0
the	0
proposed	0
method	0
can	0
decrease	0
reviewers	0
dec-	0
0	0
lination	0
rate	0
in	0
comparison	0
with	0
state-of-the-art	0
methods.	0
0	0
Relevance:	0
this	0
data	0
set	0
includes	0
86	0
papers	0
and	0
2048	0
can-	0
0	0
didate	0
reviewers.	0
As	0
it	0
is	0
often	0
difficult	0
to	0
evaluate	0
the	0
rel-	0
0	0
evance	0
between	0
a	0
paper	0
and	0
a	0
reviewer,	0
we	0
collected	0
86	0
pa-	0
0	0
pers,	0
and	0
for	0
each	0
paper	0
we	0
generated	0
30	0
reviewers	0
as	0
can-	0
0	0
didates	0
(Cf.	0
3.1).	0
Finally	0
we	0
used	0
human	0
judgments	0
as	0
0	0
ground	0
truth.	0
The	0
dataset	0
contains	0
36	0
papers	0
submitted	0
to	0
0	0
IEEE	0
TKDE,	0
IEEE	0
TBD,	0
ACM	0
TKDD,	0
ACM	0
TIST,	0
and	0
0	0
SCIS,	0
and	0
50	0
papers	0
published	0
on	0
ACM	0
KDD,	0
ICML,	0
ACL,	0
0	0
SIGGRAPH,	0
and	0
SIGCOMM.	0
We	0
asked	0
two	0
faculty	0
mem-	0
0	0
bers	0
and	0
three	0
PhD	0
students	0
from	0
the	0
authors	0
lab	0
to	0
make	0
0	0
paper-reviewer	0
relevance	0
judgments.	0
We	0
simply	0
considered	0
0	0
the	0
relevance	0
as	0
binary:	0
relevance	0
and	0
irrelevance.	0
0	0
Response:	0
this	0
data	0
set	0
was	0
collected	0
from	0
the	0
Chrome	0
ex-	0
0	0
tension.	0
It	0
includes	0
83	0
papers	0
submitted	0
to	0
a	0
number	0
of	0
differ-	0
0	0
ent	0
journals	0
and	0
367	0
reviewers	0
responses	0
(agree	0
or	0
decline).	0
0	0
Among	0
these	0
responses,	0
186	0
are	0
agree,	0
while	0
the	0
rest	0
are	0
0	0
viewed	0
as	0
decline	0
(including	0
decline,	0
unavailable	0
and	0
0	0
no	0
response).	0
0	0
On	0
both	0
data	0
sets,	0
we	0
randomly	0
selected	0
60%	0
as	0
training	0
0	0
data	0
and	0
the	0
other	0
40%	0
as	0
test	0
data.	0
We	0
perform	0
each	0
ex-	0
0	0
periment	0
10	0
times	0
(including	0
partition	0
of	0
the	0
training	0
and	0
test	0
0	0
data)	0
and	0
report	0
the	0
average	0
score.	0
0	0
Comparison	0
Methods	0
0	0
We	0
compare	0
the	0
following	0
methods	0
for	0
reviewer	0
recommen-	0
0	0
dation:	0
0	0
Content	0
Similarity	0
(Content):	0
We	0
calculate	0
similarity	0
0	0
between	0
paper	0
and	0
reviewer	0
based	0
on	0
the	0
papers	0
keywords	0
0	0
and	0
the	0
reviewers	0
research	0
interests.	0
The	0
similarity	0
score	0
0	0
Sim(p,	0
r)	0
between	0
the	0
query	0
paper	0
p	0
and	0
reviewer	0
r	0
is	0
de-	0
0	0
fined	0
based	0
on	0
Jaccard	0
similarity	0
coefficient:	0
0	0
Sim(p,	0
r)	0
=	0
0	0
K	0
p	0
I	0
r	0
0	0
K	0
p	0
I	0
r	0
0	0
(11)	0
0	0
where	0
K	0
p	0
is	0
the	0
set	0
of	0
paper	0
ps	0
keywords	0
and	0
I	0
r	0
is	0
the	0
set	0
0	0
of	0
reviewer	0
rs	0
research	0
interests	0
(also	0
represented	0
as	0
key-	0
0	0
words).	0
The	0
reviewer	0
recommendation	0
is	0
then	0
made	0
based	0
0	0
on	0
the	0
rank	0
of	0
similarity	0
score.	0
0	0
SVM-Rank:	0
The	0
Content	0
Similarity	0
method	0
does	0
not	0
use	0
0	0
training	0
data.	0
We	0
considered	0
a	0
learning	0
to	0
rank	0
approach	0
0	0
which	0
uses	0
the	0
same	0
training	0
data	0
as	0
our	0
RankFG.	0
As	0
for	0
0	0
learning	0
model,	0
we	0
used	0
the	0
implementation	0
of	0
SVM-light.	0
0	0
RankFG:	0
The	0
proposed	0
method,	0
which	0
trains	0
a	0
RankFG	0
0	0
model	0
to	0
make	0
reviewer	0
recommendations.	0
0	0
Evaluation	0
Measures	0
0	0
In	0
all	0
the	0
evaluations,	0
we	0
consider	0
the	0
problem	0
as	0
a	0
rank-	0
0	0
ing	0
problem	0
and	0
evaluate	0
different	0
methods	0
with	0
following	0
0	0
performance	0
metrics:	0
Precision	0
for	0
the	0
top-ranked	0
N	0
results	0
0	0
(P@N),	0
Mean	0
Average	0
Precision	0
(MAP),	0
and	0
R-prec	0
[Buck-	0
0	0
ley	0
and	0
Voorhees,	0
2004;	0
Craswell	0
et	0
al.,	0
2005].	0
In	0
the	0
eval-	0
0	0
uations,	0
we	0
only	0
consider	0
those	0
researchers	0
collected	0
in	0
our	0
0	0
data	0
sets.	0
0	0
All	0
the	0
experiment	0
codes	0
are	0
implemented	0
in	0
C++	0
and	0
0	0
Python,	0
and	0
the	0
evaluation	0
are	0
performed	0
on	0
an	0
x86-64	0
ma-	0
0	0
chine	0
with	0
2.70GHz	0
Intel	0
Core	0
i5	0
CPU	0
and	0
8GB	0
RAM.	0
The	0
0	0
operation	0
system	0
is	0
OS	0
X	0
10.11.2.	0
0	0
4.2	0
Performance	0
Analysis	0
0	0
We	0
compare	0
the	0
performance	0
of	0
all	0
methods	0
on	0
the	0
two	0
data	0
0	0
sets.	0
Table	0
1	0
lists	0
the	0
performance	0
of	0
comparison	0
methods	0
0	0
for	0
ranking	0
candidate	0
reviewers	0
in	0
the	0
Relevance	0
data	0
set	0
and	0
0	0
Table	0
2	0
lists	0
the	0
performance	0
of	0
declination	0
prediction	0
in	0
the	0
0	0
Response	0
data	0
set.	0
0	0
We	0
find	0
that,	0
in	0
the	0
Relevance	0
data	0
set,	0
three	0
comparison	0
0	0
methods	0
have	0
similar	0
performances.	0
This	0
is	0
reasonable,	0
as	0
0	0
the	0
relevance	0
between	0
paper	0
and	0
reviewer	0
mostly	0
depends	0
0	0
Table	0
1:	0
Results	0
of	0
reviewer	0
ranking	0
in	0
Relevance	0
(%).	0
0	0
Method	0
P@5	0
P@10	0
P@15	0
P@20	0
MAP	0
R-prec	0
0	0
Content	0
0	0
64.1	0
57.6	0
48.1	0
42.8	0
66.8	0
0	0
58.4	0
0	0
SVM-Rank	0
64.7	0
57.6	0
48.5	0
43.4	0
66.0	0
0	0
56.6	0
0	0
RankFG	0
60.0	0
57.1	0
47.9	0
43.3	0
65.1	0
0	0
58.8	0
0	0
Table	0
2:	0
Results	0
of	0
declination	0
prediction	0
in	0
Response	0
(%).	0
0	0
Method	0
0	0
P@1	0
P@3	0
P@5	0
MAP	0
R-prec	0
0	0
Content	0
0	0
55.9	0
56.9	0
59.1	0
0	0
70.1	0
0	0
56.6	0
0	0
SVM-Rank	0
52.9	0
61.8	0
64.4	0
0	0
73.2	0
0	0
59.7	0
0	0
RankFG	0
0	0
61.8	0
64.7	0
65.0	0
0	0
77.5	0
0	0
66.6	0
0	0
on	0
content	0
similarity.	0
Other	0
features	0
and	0
correlations	0
con-	0
0	0
tribute	0
little	0
to	0
the	0
relevance	0
score.	0
On	0
the	0
other	0
hand,	0
in	0
the	0
0	0
Response	0
data	0
set,	0
SVM-Rank	0
performs	0
better	0
than	0
Content	0
0	0
Similarity	0
(3.1%	0
in	0
terms	0
of	0
MAP).	0
The	0
proposed	0
RankFG	0
0	0
achieves	0
+10.6%	0
improvement	0
over	0
Content	0
and	0
+5.9%	0
over	0
0	0
SVM-Rank.	0
RankFG	0
leverages	0
the	0
correlation	0
between	0
re-	0
0	0
viewers,	0
and	0
thus	0
improves	0
the	0
performance.	0
The	0
result	0
0	0
also	0
confirms	0
the	0
discovery	0
reported	0
in	0
the	0
survey	0
[Tite	0
and	0
0	0
Schroter,	0
2007]	0
that	0
whether	0
a	0
reviewer	0
agrees	0
to	0
review	0
a	0
0	0
paper	0
depends	0
not	0
only	0
on	0
the	0
relevance	0
between	0
the	0
paper	0
0	0
content	0
and	0
the	0
reviewers	0
interests,	0
but	0
also	0
on	0
other	0
factors.	0
0	0
Factor	0
Contribution	0
Analysis	0
0	0
We	0
now	0
analyze	0
how	0
different	0
factors	0
can	0
help	0
find	0
review-	0
0	0
ers.	0
We	0
mainly	0
consider	0
three	0
factors	0
as	0
features:	0
basic	0
statis-	0
0	0
tics	0
(S),	0
expertise	0
matching	0
(E),	0
and	0
organization	0
(O).	0
Here	0
0	0
we	0
examine	0
the	0
contribution	0
of	0
different	0
factors	0
by	0
removing	0
0	0
each	0
factor	0
and	0
testing	0
the	0
RankFG	0
performance.	0
Figure	0
2	0
0	0
shows	0
the	0
factor	0
contribution	0
analysis	0
result,	0
using	0
MAP	0
0	0
score	0
as	0
the	0
evaluation	0
metric.	0
In	0
particular,	0
RankFG-S	0
repre-	0
0	0
sents	0
that	0
removing	0
basic	0
statistical	0
features	0
from	0
our	0
model,	0
0	0
RankFG-E	0
represents	0
removing	0
expertise	0
matching	0
features,	0
0	0
and	0
RankFG-O	0
means	0
removing	0
organization	0
features.	0
0	0
From	0
Figure	0
2,	0
we	0
can	0
see	0
that	0
in	0
the	0
Relevance	0
data	0
set,	0
0	0
the	0
performance	0
mainly	0
depends	0
on	0
expertise	0
matching.	0
In	0
0	0
other	0
word,	0
the	0
similarity	0
between	0
a	0
papers	0
keywords	0
and	0
0	0
a	0
reviewers	0
interests.	0
Removing	0
statistical	0
or	0
organization	0
0	0
features	0
does	0
not	0
significantly	0
affect	0
the	0
performance.	0
In	0
the	0
0	0
Response	0
data	0
set,	0
the	0
situation	0
is	0
very	0
different.	0
When	0
we	0
0	0
remove	0
expertise	0
matching	0
features,	0
the	0
MAP	0
score	0
does	0
not	0
0	0
decrease,	0
but	0
rather	0
increases	0
1.1%.	0
It	0
might	0
be	0
because	0
in	0
0	0
our	0
collected	0
data,	0
all	0
the	0
reviewers	0
are	0
selected	0
by	0
journal	0
0	0
editors,	0
which	0
means	0
that	0
all	0
these	0
reviewers	0
can	0
be	0
consid-	0
0	0
ered	0
relevant	0
to	0
the	0
paper.	0
Besides,	0
it	0
can	0
be	0
seen	0
that	0
the	0
0	0
MAP	0
score	0
drops	0
significantly	0
when	0
ignoring	0
statistical	0
or	0
or-	0
0	0
ganization	0
features.	0
This	0
confirms	0
that	0
our	0
model	0
works	0
well	0
0	0
when	0
combining	0
these	0
features	0
together.	0
0	0
Convergence	0
Analysis	0
0	0
We	0
conduct	0
an	0
experiment	0
to	0
analyze	0
the	0
convergent	0
prop-	0
0	0
erty	0
of	0
the	0
RankFG	0
model.	0
Figure	0
3	0
shows	0
the	0
convergence	0
0	0
performance	0
of	0
the	0
RankFG	0
learning	0
algorithm.	0
In	0
the	0
Rele-	0
0	0
vance	0
data	0
set,	0
the	0
MAP	0
score	0
keeps	0
increasing	0
along	0
with	0
the	0
0	0
number	0
of	0
iterations,	0
and	0
finally	0
converges	0
after	0
1800	0
itera-	0
0	0
Relevance	0
0	0
Response	0
0	0
Mean	0
Average	0
Precision	0
0	0
0.4	0
0	0
0.45	0
0	0
0.5	0
0	0
0.55	0
0	0
0.6	0
0	0
0.65	0
0	0
0.7	0
0	0
0.75	0
0	0
0.8	0
0	0
0.85	0
0	0
RankFG	0
0	0
RankFG-S	0
0	0
RankFG-E	0
0	0
RankFG-O	0
0	0
Figure	0
2:	0
Factor	0
contribution	0
analysis:	0
RankFG-S	0
stands	0
0	0
for	0
ignoring	0
statistics;	0
Rank-E	0
stands	0
for	0
ignoring	0
expertise	0
0	0
matching;	0
Rank-O	0
stands	0
for	0
ignoring	0
organization.	0
0	0
#iterations	0
0	0
0	0
0	0
500	0
0	0
1000	0
0	0
1500	0
0	0
2000	0
0	0
Mean	0
Average	0
Precision	0
0	0
0.5	0
0	0
0.55	0
0	0
0.6	0
0	0
0.65	0
0	0
0.7	0
0	0
0.75	0
0	0
0.8	0
0	0
0.85	0
0	0
Relevance	0
0	0
Response	0
0	0
Figure	0
3:	0
Convergence	0
analysis	0
of	0
RankFG	0
model.	0
0	0
tions.	0
In	0
the	0
Response	0
data	0
set,	0
the	0
RankFG	0
quickly	0
reaches	0
a	0
0	0
relatively	0
stable	0
result	0
(after	0
only	0
200	0
iterations),	0
though	0
does	0
0	0
not	0
really	0
converge.	0
0	0
Training/Test	0
Ratio	0
Analysis	0
0	0
We	0
provide	0
further	0
analysis	0
on	0
the	0
effect	0
of	0
the	0
training	0
ratio	0
0	0
on	0
our	0
RankFG	0
model.	0
Figure	0
4	0
shows	0
the	0
experiment	0
results	0
0	0
when	0
varying	0
the	0
percentage	0
of	0
training	0
data.	0
In	0
the	0
Response	0
0	0
data	0
set,	0
we	0
see	0
a	0
rising	0
trend	0
as	0
the	0
percentage	0
of	0
training	0
0	0
data	0
increases.	0
This	0
indicates	0
the	0
positive	0
effect	0
of	0
training	0
0	0
data	0
size	0
on	0
the	0
recommendation	0
performance	0
of	0
our	0
model.	0
0	0
5	0
Related	0
Work	0
0	0
The	0
research	0
of	0
matching	0
papers	0
with	0
reviewers	0
can	0
be	0
traced	0
0	0
back	0
to	0
20	0
years	0
ago.	0
In	0
general,	0
existing	0
methods	0
for	0
exper-	0
0	0
tise	0
matching	0
mainly	0
fall	0
into	0
two	0
categories:	0
probabilistic	0
0	0
models	0
and	0
optimization	0
models.	0
0	0
Probabilistic	0
models	0
try	0
to	0
improve	0
the	0
matching	0
accuracy	0
0	0
between	0
experts	0
and	0
papers	0
based	0
on	0
different	0
probabilis-	0
0	0
tic	0
models,	0
such	0
as	0
keyword	0
matching	0
[Haym	0
et	0
al.,	0
1999],	0
0	0
latent	0
semantic	0
indexing	0
[Dumais	0
and	0
Nielsen,	0
1992],	0
and	0
0	0
probabilistic	0
topic	0
modeling	0
[Karimzadehgan	0
et	0
al.,	0
2008;	0
0	0
Training	0
percentage	0
0	0
0.1	0
0	0
0.2	0
0	0
0.3	0
0	0
0.4	0
0	0
0.5	0
0	0
0.6	0
0	0
0.7	0
0	0
0.8	0
0	0
Mean	0
Average	0
Precision	0
0	0
0.5	0
0	0
0.55	0
0	0
0.6	0
0	0
0.65	0
0	0
0.7	0
0	0
0.75	0
0	0
0.8	0
0	0
Relevance	0
0	0
Response	0
0	0
Figure	0
4:	0
Training/test	0
ratio	0
analysis	0
of	0
RankFG	0
model.	0
0	0
Mimno	0
and	0
McCallum,	0
2007].	0
These	0
works	0
are	0
similar	0
to	0
0	0
expert	0
finding	0
problems,	0
which	0
always	0
use	0
language	0
models	0
0	0
or	0
topic	0
models.	0
0	0
The	0
optimization	0
model	0
considers	0
the	0
constraints	0
in	0
con-	0
0	0
ference	0
paper-reviewer	0
assignment	0
tasks.	0
These	0
models	0
con-	0
0	0
centrate	0
on	0
solving	0
the	0
optimization	0
problem	0
of	0
construct-	0
0	0
ing	0
panels	0
between	0
a	0
list	0
of	0
reviewers	0
and	0
a	0
list	0
of	0
papers,	0
0	0
for	0
example	0
integer	0
linear	0
programming	0
[Karimzadehgan	0
and	0
0	0
Zhai,	0
2009]	0
and	0
minimum	0
cost	0
flow	0
[Hartvigsen	0
et	0
al.,	0
1999;	0
0	0
Tang	0
et	0
al.,	0
2012].	0
0	0
Recently,	0
a	0
few	0
systems	0
have	0
also	0
been	0
developed	0
to	0
make	0
0	0
reviewer	0
recommendation	0
[Yang	0
et	0
al.,	0
2009],	0
or	0
help	0
with	0
0	0
conference	0
reviewer	0
assignment	0
[Hettich	0
and	0
Pazzani,	0
2006;	0
0	0
Conry	0
et	0
al.,	0
2009;	0
Mauro	0
et	0
al.,	0
2005;	0
Benferhat	0
and	0
Lang,	0
0	0
2001].	0
Wu	0
et	0
al.	0
[2013]	0
presents	0
a	0
patent	0
partner	0
recommen-	0
0	0
dation	0
framework	0
in	0
enterprise	0
social	0
networks,	0
which	0
also	0
0	0
uses	0
a	0
ranking	0
factor	0
graph	0
model.	0
0	0
In	0
this	0
paper,	0
our	0
general	0
goal	0
is	0
to	0
recommend	0
appropriate	0
0	0
reviewers	0
to	0
a	0
given	0
paper	0
and	0
predict	0
the	0
willingness	0
of	0
the	0
0	0
reviewers	0
to	0
accept	0
or	0
decline	0
a	0
review	0
invitation.	0
0	0
6	0
Conclusions	0
0	0
In	0
this	0
paper,	0
we	0
study	0
a	0
novel	0
problem	0
of	0
learning	0
to	0
perform	0
0	0
declination	0
prediction	0
in	0
peer	0
review	0
requests.	0
We	0
formalize	0
0	0
the	0
problem	0
as	0
a	0
ranking	0
problem,	0
and	0
propose	0
a	0
ranking	0
fac-	0
0	0
tor	0
graph	0
(RankFG)	0
model	0
to	0
predict	0
how	0
likely	0
a	0
candidate	0
0	0
reviewer	0
would	0
be	0
to	0
accept	0
(or	0
decline)	0
a	0
review	0
invitation.	0
0	0
RankFG	0
leverages	0
correlation	0
between	0
reviewers	0
to	0
improve	0
0	0
prediction	0
accuracy.	0
We	0
also	0
develop	0
an	0
efficient	0
algorithm	0
0	0
to	0
interactively	0
train	0
the	0
RankFG	0
model.	0
It	0
is	0
often	0
difficult	0
to	0
0	0
find	0
a	0
ground	0
truth	0
data	0
to	0
evaluate	0
such	0
task.	0
To	0
fairly	0
eval-	0
0	0
uate	0
the	0
proposed	0
methodologies,	0
we	0
developed	0
a	0
Chrome	0
0	0
Extension	0
of	0
reviewer	0
recommendation	0
and	0
deployed	0
it	0
in	0
0	0
the	0
Google	0
Chrome	0
Web	0
Store.	0
More	0
than	0
20	0
editors	0
down-	0
0	0
loaded	0
the	0
extension	0
and	0
used	0
it	0
for	0
reviewer	0
recommenda-	0
0	0
tions.	0
Based	0
on	0
the	0
feedback/track	0
logs,	0
we	0
compare	0
the	0
pro-	0
0	0
posed	0
method	0
with	0
several	0
state-of-the-art	0
methods.	0
Exper-	0
0	0
iments	0
show	0
that	0
our	0
method	0
can	0
significantly	0
improve	0
(5-	0
0	0
10%)	0
the	0
accuracy	0
of	0
declination	0
prediction.	0
0	0
References	0
0	0
[Benferhat	0
and	0
Lang,	0
2001]	0
Salem	0
Benferhat	0
and	0
J	0
er	0
ome	0
0	0
Lang.	0
Conference	0
paper	0
assignment.	0
Int.	0
J.	0
Intell.	0
Syst.,	0
0	0
16(10):11831192,	0
2001.	0
0	0
[Buckley	0
and	0
Voorhees,	0
2004]	0
Chris	0
Buckley	0
and	0
Ellen	0
M.	0
0	0
Voorhees.	0
Retrieval	0
evaluation	0
with	0
incomplete	0
informa-	0
0	0
tion.	0
In	0
Proc.	0
of	0
SIGIR04,	0
pages	0
2532,	0
2004.	0
0	0
[Conry	0
et	0
al.,	0
2009]	0
Don	0
Conry,	0
Yehuda	0
Koren,	0
and	0
Naren	0
0	0
Ramakrishnan.	0
Recommender	0
systems	0
for	0
the	0
conference	0
0	0
paper	0
assignment	0
problem.	0
In	0
RecSys09,	0
pages	0
357360,	0
0	0
2009.	0
0	0
[Craswell	0
et	0
al.,	0
2005]	0
Nick	0
Craswell,	0
Arjen	0
P.	0
de	0
Vries,	0
and	0
0	0
Ian	0
Soboroff.	0
Overview	0
of	0
the	0
trec-2005	0
enterprise	0
track.	0
0	0
In	0
TREC	0
2005	0
Conference	0
Notebook,	0
pages	0
199205,	0
0	0
2005.	0
0	0
[Dumais	0
and	0
Nielsen,	0
1992]	0
Susan	0
T.	0
Dumais	0
and	0
Jakob	0
0	0
Nielsen.	0
0	0
Automating	0
the	0
assignment	0
of	0
submitted	0
0	0
manuscripts	0
to	0
reviewers.	0
In	0
SIGIR92,	0
pages	0
233244,	0
0	0
1992.	0
0	0
[Hartvigsen	0
et	0
al.,	0
1999]	0
David	0
Hartvigsen,	0
Jerry	0
C.	0
Wei,	0
0	0
and	0
Richard	0
Czuchlewski.	0
The	0
conference	0
paper-reviewer	0
0	0
assignment	0
problem.	0
Decision	0
Sciences,	0
30(3):865876,	0
0	0
1999.	0
0	0
[Haym	0
et	0
al.,	0
1999]	0
Chumki	0
Basu	0
Haym,	0
Haym	0
Hirsh,	0
0	0
William	0
W.	0
Cohen,	0
and	0
Craig	0
Nevill-manning.	0
Recom-	0
0	0
mending	0
papers	0
by	0
mining	0
the	0
web.	0
In	0
IJCAI99,	0
pages	0
0	0
111,	0
1999.	0
0	0
[Hettich	0
and	0
Pazzani,	0
2006]	0
Seth	0
Hettich	0
and	0
Michael	0
J.	0
0	0
Pazzani.	0
Mining	0
for	0
proposal	0
reviewers:	0
lessons	0
learned	0
at	0
0	0
the	0
national	0
science	0
foundation.	0
In	0
KDD06,	0
pages	0
862	0
0	0
871,	0
2006.	0
0	0
[Karimzadehgan	0
and	0
Zhai,	0
2009]	0
Maryam	0
Karimzadehgan	0
0	0
and	0
ChengXiang	0
Zhai.	0
Constrained	0
multi-aspect	0
expertise	0
0	0
matching	0
for	0
committee	0
review	0
assignment.	0
In	0
CIKM09,	0
0	0
pages	0
16971700,	0
2009.	0
0	0
[Karimzadehgan	0
et	0
al.,	0
2008]	0
Maryam	0
0	0
Karimzadehgan,	0
0	0
ChengXiang	0
Zhai,	0
and	0
Geneva	0
Belford.	0
Multi-aspect	0
0	0
expertise	0
matching	0
for	0
review	0
assignment.	0
In	0
CIKM08,	0
0	0
pages	0
11131122,	0
2008.	0
0	0
[Kassirer	0
and	0
Campion,	0
1994]	0
Jerome	0
P	0
Kassirer	0
and	0
Ed-	0
0	0
ward	0
W	0
Campion.	0
Peer	0
review:	0
crude	0
and	0
understudied,	0
0	0
but	0
indispensable.	0
Jama,	0
272(2):9697,	0
1994.	0
0	0
[Kindermann	0
et	0
al.,	0
1980]	0
Ross	0
Kindermann,	0
James	0
Laurie	0
0	0
Snell,	0
et	0
al.	0
Markov	0
random	0
fields	0
and	0
their	0
applications,	0
0	0
volume	0
1.	0
American	0
Mathematical	0
Society	0
Providence,	0
0	0
1980.	0
0	0
[Kschischang	0
et	0
al.,	0
2001]	0
Frank	0
R	0
Kschischang,	0
Brendan	0
J	0
0	0
Frey,	0
and	0
Hans-Andrea	0
Loeliger.	0
Factor	0
graphs	0
and	0
the	0
0	0
sum-product	0
algorithm.	0
Information	0
Theory,	0
IEEE	0
Trans-	0
0	0
actions	0
on,	0
47(2):498519,	0
2001.	0
0	0
[Mauro	0
et	0
al.,	0
2005]	0
Nicola	0
Di	0
Mauro,	0
Teresa	0
Maria	0
Al-	0
0	0
tomare	0
Basile,	0
and	0
Stefano	0
Ferilli.	0
Grape:	0
An	0
expert	0
re-	0
0	0
view	0
assignment	0
component	0
for	0
scientific	0
conference	0
man-	0
0	0
agement	0
systems.	0
In	0
IEA/AIE05,	0
pages	0
789798,	0
2005.	0
0	0
[Mimno	0
and	0
McCallum,	0
2007]	0
David	0
Mimno	0
and	0
Andrew	0
0	0
McCallum.	0
Expertise	0
modeling	0
for	0
matching	0
papers	0
with	0
0	0
reviewers.	0
In	0
SIGKDD07,	0
pages	0
500509,	0
2007.	0
0	0
[Rennie,	0
1999]	0
Drummond	0
Rennie.	0
Editorial	0
peer	0
review:	0
its	0
0	0
development	0
and	0
rationale.	0
Peer	0
review	0
in	0
health	0
sciences.	0
0	0
London:	0
BMJ	0
Books,	0
pages	0
313,	0
1999.	0
0	0
[Smith,	0
1997]	0
Richard	0
Smith.	0
Peer	0
review:	0
reform	0
or	0
rev-	0
0	0
olution?	0
BMJ:	0
British	0
Medical	0
Journal,	0
315(7111):759,	0
0	0
1997.	0
0	0
[Sun	0
et	0
al.,	0
2007]	0
Yong-Hong	0
Sun,	0
Jian	0
Ma,	0
Zhi-Ping	0
Fan,	0
0	0
and	0
Jun	0
Wang.	0
A	0
hybrid	0
knowledge	0
and	0
model	0
approach	0
0	0
for	0
reviewer	0
assignment.	0
In	0
HICSS07,	0
pages	0
4747,	0
2007.	0
0	0
[Tang	0
et	0
al.,	0
2012]	0
Wenbin	0
Tang,	0
Jie	0
Tang,	0
Tao	0
Lei,	0
Chen-	0
0	0
hao	0
Tan,	0
Bo	0
Gao,	0
and	0
Tian	0
Li.	0
On	0
optimization	0
of	0
exper-	0
0	0
tise	0
matching	0
with	0
various	0
constraints.	0
Neurocomputing,	0
0	0
76(1):7183,	0
2012.	0
0	0
[Tite	0
and	0
Schroter,	0
2007]	0
Leanne	0
Tite	0
and	0
Sara	0
Schroter.	0
0	0
Why	0
do	0
peer	0
reviewers	0
decline	0
to	0
review?	0
a	0
survey.	0
Jour-	0
0	0
nal	0
of	0
epidemiology	0
and	0
community	0
health,	0
61(1):912,	0
0	0
2007.	0
0	0
[Wu	0
et	0
al.,	0
2013]	0
Sen	0
Wu,	0
Jimeng	0
Sun,	0
and	0
Jie	0
Tang.	0
Patent	0
0	0
partner	0
recommendation	0
in	0
enterprise	0
social	0
networks.	0
In	0
0	0
WSDM13,	0
pages	0
4352,	0
2013.	0
0	0
[Yang	0
et	0
al.,	0
2009]	0
Kai-Hsiang	0
Yang,	0
Tai-Liang	0
Kuo,	0
Hahn-	0
0	0
Ming	0
Lee,	0
and	0
Jan-Ming	0
Ho.	0
A	0
reviewer	0
recommenda-	0
0	0
tion	0
system	0
based	0
on	0
collaborative	0
intelligence.	0
In	0
Web	0
0	0
Intelligence	0
and	0
Intelligent	0
Agent	0
Technologies,	0
2009.	0
WI-	0
0	0
IAT09.	0
IEEE/WIC/ACM	0
International	0
Joint	0
Conferences	0
0	0
on,	0
volume	0
1,	0
pages	0
564567.	0
IET,	0
2009.	0
0	0
[Yedidia	0
et	0
al.,	0
2000]	0
Jonathan	0
S	0
Yedidia,	0
William	0
T	0
Free-	0
0	0
man,	0
Yair	0
Weiss,	0
et	0
al.	0
Generalized	0
belief	0
propagation.	0
In	0
0	0
NIPS,	0
volume	0
13,	0
pages	0
689695,	0
2000.	0
0	0
[Zhai	0
and	0
Lafferty,	0
2001]	0
Chengxiang	0
Zhai	0
and	0
John	0
Laf-	0
0	0
ferty.	0
A	0
study	0
of	0
smoothing	0
methods	0
for	0
language	0
mod-	0
0	0
els	0
applied	0
to	0
ad	0
hoc	0
information	0
retrieval.	0
In	0
SIGIR01,	0
0	0
pages	0
334342,	0
2001.	0
0	0
[Zhang	0
et	0
al.,	0
2006]	0
Kuo	0
Zhang,	0
Hui	0
Xu,	0
Jie	0
Tang,	0
and	0
0	0
Juanzi	0
Li.	0
Keyword	0
extraction	0
using	0
support	0
vector	0
ma-	0
0	0
chine.	0
In	0
WAIM06,	0
pages	0
8596,	0
2006.	0
0	0
